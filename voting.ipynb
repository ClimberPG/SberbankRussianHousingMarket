{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bruno_model = pd.read_csv(\"../models/bruno_model.csv\")\n",
    "ensemble_model = pd.read_csv(\"../models/ensemble_model.csv\")\n",
    "climberpg_model = pd.read_csv(\"../models/climberpg_model.csv\")\n",
    "pca_model = pd.read_csv(\"../models/pca_model.csv\")\n",
    "jason_model = pd.read_csv(\"../models/jason_model.csv\")\n",
    "reynaldo_model = pd.read_csv(\"../models/reynaldo_model.csv\")\n",
    "vivek_model = pd.read_csv(\"../models/vivek_model.csv\")\n",
    "randomforest_model = pd.read_csv(\"../models/randomforest_model.csv\")\n",
    "extratrees_model = pd.read_csv(\"../models/extratrees_model.csv\")\n",
    "kaggle_model = pd.read_csv(\"../models/kaggle_model.csv\")\n",
    "my_model = pd.read_csv(\"../models/my_model.csv\")\n",
    "my2_model = pd.read_csv(\"../models/my2_model.csv\")\n",
    "my3_model = pd.read_csv(\"../models/my3_model.csv\")\n",
    "my4_model = pd.read_csv(\"../models/my4_model.csv\")\n",
    "my5_model = pd.read_csv(\"../models/my5_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruno_model.price_doc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = bruno_model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output['price_doc'] = bruno_model.price_doc * 0.15 + ensemble_model.price_doc * 0.1 + my2_model.price_doc * 0.1 + \\\n",
    "my3_model.price_doc * 0.05 + jason_model.price_doc * 0.1 + reynaldo_model.price_doc * 0.4 + \\\n",
    "my4_model.price_doc * 0.05 + my5_model.price_doc * 0.05\n",
    "# + pca_model.price_doc * 0.025 + vivek_model.price_doc * 0.025 + \\\n",
    "# extratrees_model.price_doc * 0.025 + randomforest_model.price_doc * 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('votingSub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.price_doc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "micro_humility_factor = 1     #    range from 0 (complete humility) to 1 (no humility)\n",
    "macro_humility_factor = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing\n",
    "import xgboost as xgb\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "macro = pd.read_csv('../data/macro.csv')\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "id_test = test.id\n",
    "\n",
    "# Macro data monthly medians\n",
    "macro[\"timestamp\"] = pd.to_datetime(macro[\"timestamp\"])\n",
    "macro[\"year\"]  = macro[\"timestamp\"].dt.year\n",
    "macro[\"month\"] = macro[\"timestamp\"].dt.month\n",
    "macro[\"yearmonth\"] = 100*macro.year + macro.month\n",
    "macmeds = macro.groupby(\"yearmonth\").median()\n",
    "\n",
    "# Price data monthly medians\n",
    "train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "train[\"year\"]  = train[\"timestamp\"].dt.year\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "train[\"yearmonth\"] = 100*train.year + train.month\n",
    "prices = train[[\"yearmonth\",\"price_doc\"]]\n",
    "p = prices.groupby(\"yearmonth\").median()\n",
    "\n",
    "# Join monthly prices to macro data\n",
    "df = macmeds.join(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to process Almon lags\n",
    "\n",
    "import numpy.matlib as ml\n",
    " \n",
    "def almonZmatrix(X, maxlag, maxdeg):\n",
    "    \"\"\"\n",
    "    Creates the Z matrix corresponding to vector X.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    Z = ml.zeros((len(X)-maxlag, maxdeg+1))\n",
    "    for t in range(maxlag,  n):\n",
    "       #Solve for Z[t][0].\n",
    "       Z[t-maxlag,0] = sum([X[t-lag] for lag in range(maxlag+1)])\n",
    "       for j in range(1, maxdeg+1):\n",
    "             s = 0.0\n",
    "             for i in range(1, maxlag+1):       \n",
    "                s += (i)**j * X[t-i]\n",
    "             Z[t-maxlag,j] = s\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for macro model\n",
    "y = df.price_doc.div(df.cpi).apply(np.log).loc[201108:201506]\n",
    "lncpi = df.cpi.apply(np.log)\n",
    "tblags = 5    # Number of lags used on PDL for Trade Balance\n",
    "mrlags = 5    # Number of lags used on PDL for Mortgage Rate\n",
    "cplags = 5    # Number of lags used on PDL for CPI\n",
    "ztb = almonZmatrix(df.balance_trade.loc[201103:201506].as_matrix(), tblags, 1)\n",
    "zmr = almonZmatrix(df.mortgage_rate.loc[201103:201506].as_matrix(), mrlags, 1)\n",
    "zcp = almonZmatrix(lncpi.loc[201103:201506].as_matrix(), cplags, 1)\n",
    "columns = ['tb0', 'tb1', 'mr0', 'mr1', 'cp0', 'cp1']\n",
    "z = pd.DataFrame( np.concatenate( (ztb, zmr, zcp), axis=1), y.index.values, columns )\n",
    "X = sm.add_constant( z )\n",
    "\n",
    "# Fit macro model\n",
    "eq = sm.OLS(y, X)\n",
    "fit = eq.fit()\n",
    "\n",
    "# Predict with macro model\n",
    "test_cpi = df.cpi.loc[201507:201605]\n",
    "test_index = test_cpi.index\n",
    "ztb_test = almonZmatrix(df.balance_trade.loc[201502:201605].as_matrix(), tblags, 1)\n",
    "zmr_test = almonZmatrix(df.mortgage_rate.loc[201502:201605].as_matrix(), mrlags, 1)\n",
    "zcp_test = almonZmatrix(lncpi.loc[201502:201605].as_matrix(), cplags, 1)\n",
    "z_test = pd.DataFrame( np.concatenate( (ztb_test, zmr_test, zcp_test), axis=1), \n",
    "                       test_index, columns )\n",
    "X_test = sm.add_constant( z_test )\n",
    "pred_lnrp = fit.predict( X_test )\n",
    "pred_p = np.exp(pred_lnrp) * test_cpi\n",
    "\n",
    "# Merge with test cases and compute mean for macro prediction\n",
    "test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n",
    "test[\"year\"]  = test[\"timestamp\"].dt.year\n",
    "test[\"month\"] = test[\"timestamp\"].dt.month\n",
    "test[\"yearmonth\"] = 100*test.year + test.month\n",
    "test_ids = test[[\"yearmonth\",\"id\"]]\n",
    "monthprices = pd.DataFrame({\"yearmonth\":pred_p.index.values,\"monthprice\":pred_p.values})\n",
    "macro_mean = np.exp(test_ids.merge(monthprices, on=\"yearmonth\").monthprice.apply(np.log).mean())\n",
    "macro_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive macro model assumes housing prices will simply follow CPI\n",
    "naive_pred_lnrp = y.mean()\n",
    "naive_pred_p = np.exp(naive_pred_lnrp) * test_cpi\n",
    "monthnaive = pd.DataFrame({\"yearmonth\":pred_p.index.values, \"monthprice\":naive_pred_p.values})\n",
    "macro_naive = np.exp(test_ids.merge(monthnaive, on=\"yearmonth\").monthprice.apply(np.log).mean())\n",
    "macro_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine naive and substantive macro models\n",
    "macro_mean = macro_naive * (macro_mean/macro_naive) ** macro_humility_factor\n",
    "macro_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust\n",
    "\n",
    "lny = np.log(output.price_doc)\n",
    "lnm = np.log(macro_mean)\n",
    "\n",
    "# I'm not sure whether this makes any sense or not.\n",
    "# 1+lny.mean()-lnm term is meant to offest the scale effect of the logarithmic mean shift\n",
    "#   while allowing the new logarithmic mean to remain at lnm.\n",
    "y_trans = lnm  +  micro_humility_factor * (lny-lny.mean()) * (1+lny.mean()-lnm)\n",
    "y_predict = np.exp( y_trans )\n",
    "\n",
    "sub = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('votingSub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.price_doc.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
