{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing, ensemble\n",
    "from numpy import nan\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from com_util import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # ingore warnings\n",
    "%matplotlib inline\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['brent', 'eurrub', 'usdrub', 'micex_cbi_tr', 'micex_rgbi_tr','micex',  'brent', 'rts', 'oil_urals',\n",
    "        'balance_trade', 'ppi', 'cpi', 'gdp_quart', 'net_capital_export', 'micex_cbi_tr', 'deposits_rate',\n",
    "       'gdp_quart_growth', 'mortgage_rate', 'average_provision_of_build_contract_moscow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train.csv\", parse_dates=['timestamp'])\n",
    "df_test = pd.read_csv(\"../data/test.csv\", parse_dates=['timestamp'])\n",
    "df_macro = pd.read_csv(\"../data/macro.csv\", parse_dates=['timestamp'], usecols=['timestamp']+cols)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # fix bad address\n",
    "# fx = pd.read_excel('../data/BAD_ADDRESS_FIX.xlsx').drop_duplicates('id').set_index('id')\n",
    "# df_train.update(fx, overwrite=True)\n",
    "# df_test.update(fx, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_loc = pd.read_csv(\"../data/train_lat_lon.csv\")\n",
    "df_test_loc = pd.read_csv(\"../data/test_lat_lon.csv\")\n",
    "df_train = df_train.merge(df_train_loc, on='id')\n",
    "df_train.drop(['key', 'tolerance_m'], axis=1, inplace=True)\n",
    "df_test = df_test.merge(df_test_loc, on='id')\n",
    "df_test.drop(['key', 'tolerance_m'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # undersampling by magic numbers\n",
    "# trainsub = df_train[df_train.timestamp < '2015-01-01']\n",
    "# trainsub = trainsub[trainsub.product_type==\"Investment\"]\n",
    "\n",
    "# ind_1m = trainsub[trainsub.price_doc <= 1000000].index\n",
    "# ind_2m = trainsub[trainsub.price_doc == 2000000].index\n",
    "# ind_3m = trainsub[trainsub.price_doc == 3000000].index\n",
    "\n",
    "# train_index = set(df_train.index.copy())\n",
    "\n",
    "# for ind, gap in zip([ind_1m, ind_2m, ind_3m], [10, 3, 2]):\n",
    "#     ind_set = set(ind)\n",
    "#     ind_set_cut = ind.difference(set(ind[::gap]))\n",
    "\n",
    "#     train_index = train_index.difference(ind_set_cut)\n",
    "\n",
    "# df_train = df_train.loc[train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['price_doc'].values\n",
    "id_test = df_test['id']\n",
    "\n",
    "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "df_test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Build df_all = (df_train+df_test).join(df_macro)\n",
    "num_train = len(df_train)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "df_all = df_all.merge(df_macro, on='timestamp')\n",
    "\n",
    "# Add month-year count\n",
    "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "df_all['month'] = df_all.timestamp.dt.month\n",
    "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
    "\n",
    "print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import missingno as msno\n",
    "# missingValueColumns = df_macro.columns[df_macro.isnull().any()].tolist()\n",
    "# msno.bar(df_macro[missingValueColumns],\\\n",
    "#             figsize=(20,8),color=(0.5, 0.5, 1),fontsize=12,labels=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouped_df = df_train.groupby('timestamp')['price_doc'].aggregate(np.median).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8))\n",
    "# sns.barplot(grouped_df.timestamp.values, grouped_df.price_doc.values, alpha=0.8, color=color[2])\n",
    "# plt.ylabel('Median Price', fontsize=12)\n",
    "# plt.xlabel('Year Month', fontsize=12)\n",
    "# plt.xticks(rotation='vertical')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing some cleaning of square\n",
    "df_all['full_sq'].ix[df_all.full_sq > 1000] = nan\n",
    "df_all['life_sq'].ix[df_all.life_sq > 1000] = nan\n",
    "\n",
    "df_all['life_sq'].ix[df_all.full_sq < df_all.life_sq] = nan\n",
    "df_all['life_sq'].ix[df_all.life_sq < 5] = nan\n",
    "df_all['full_sq'].ix[df_all.full_sq < 5] = nan\n",
    "df_all['kitch_sq'].ix[df_all.kitch_sq > df_all.life_sq] = nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cleaning build_year\n",
    "df_all['build_year'].ix[df_all.build_year == 20052009] = 2007\n",
    "df_all['build_year'].ix[df_all.build_year < 1500] = nan\n",
    "df_all['build_year'].ix[df_all.build_year > 2500] = nan\n",
    "\n",
    "# cleaning state\n",
    "df_all['state'].ix[df_all.state == 33] = 3\n",
    "\n",
    "# cleaning floor\n",
    "df_all['max_floor'].ix[df_all.max_floor == 0] = nan\n",
    "df_all['floor'].ix[df_all.floor == 0] = nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some FE ideas from discussion && kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate full_sq\n",
    "df_all['full_sq_separate'] = df_all['full_sq'].copy()\n",
    "\n",
    "for i in range(30):\n",
    "    df_all['full_sq_separate'].ix[(df_all.full_sq > (i+1)*5) & (df_all.full_sq <= ((i+1)*5+5))] = \\\n",
    "    len(df_all['full_sq'].ix[(df_all.full_sq > (i+1)*5) & (df_all.full_sq <= ((i+1)*5+5))])\n",
    "    \n",
    "df_all['full_sq_separate'].ix[df_all.full_sq <= 5] = len(df_all['full_sq'].ix[df_all.full_sq <= 5])\n",
    "df_all['full_sq_separate'].ix[df_all.full_sq <= 5] = len(df_all['full_sq'].ix[df_all.full_sq > 155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['life_sq_separate'] = df_all['life_sq'].copy()\n",
    "\n",
    "for i in range(30):\n",
    "    df_all['life_sq_separate'].ix[(df_all.life_sq > (i+1)*5) & (df_all.life_sq <= ((i+1)*5+5))] = \\\n",
    "    len(df_all['life_sq'].ix[(df_all.life_sq > (i+1)*5) & (df_all.life_sq <= ((i+1)*5+5))])\n",
    "    \n",
    "df_all['life_sq_separate'].ix[df_all.life_sq <= 5] = len(df_all['life_sq'].ix[df_all.life_sq <= 5])\n",
    "df_all['life_sq_separate'].ix[df_all.life_sq <= 5] = len(df_all['life_sq'].ix[df_all.life_sq > 155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add null value counts\n",
    "df_all['null_count'] = df_all.isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove timestamp column (may overfit the model in train)\n",
    "df_all.drop(['timestamp'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#每个经纬度分类一下（1平方千米一个类）\n",
    "df_all[\"jwd_class\"]=map(lambda x,y:(int(x*100)%100)*100+(int(-y*100)%100),df_all[\"lat\"].fillna(0),df_all[\"lon\"].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GroupBy 经纬度\n",
    "df_all = merge_median(df_all, [\"jwd_class\"], \"full_sq\", \"fullsq_median_jwd\")\n",
    "df_all = merge_median(df_all, [\"jwd_class\"], \"life_sq\", \"lifesq_median_jwd\")\n",
    "df_all = merge_median(df_all, [\"jwd_class\"], \"floor\", \"floor_median_jwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8))\n",
    "# sns.countplot(x=\"usdrub\", data=df_macro)\n",
    "# plt.ylabel('Count', fontsize=12)\n",
    "# plt.xlabel('Variable', fontsize=12)\n",
    "# plt.xticks(rotation='vertical')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8))\n",
    "# sns.countplot(x=\"full_sq_separate\", data=df_all)\n",
    "# plt.ylabel('Count', fontsize=12)\n",
    "# plt.xlabel('Variable', fontsize=12)\n",
    "# plt.xticks(rotation='vertical')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureImportance = model.get_fscore()\n",
    "features = pd.DataFrame()\n",
    "features['features'] = featureImportance.keys()\n",
    "features['importance'] = featureImportance.values()\n",
    "features.sort_values(by=['importance'],ascending=False,inplace=True)\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "plt.xticks(rotation=60)\n",
    "sn.barplot(data=features.head(30),x=\"features\",y=\"importance\",ax=ax,orient=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topFeatures = features[\"features\"].tolist()[:15]\n",
    "topFeatures.append(\"price_doc\")\n",
    "corrMatt = train[topFeatures].corr()\n",
    "mask = np.array(corrMatt)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "sn.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with categorical values\n",
    "df_numeric = df_all.select_dtypes(exclude=['object'])\n",
    "df_obj = df_all.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for c in df_obj:\n",
    "    df_obj[c] = pd.factorize(df_obj[c])[0]\n",
    "\n",
    "df_values = pd.concat([df_numeric, df_obj], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dealing with missed values\n",
    "# from sklearn.base import TransformerMixin\n",
    "# class DataFrameImputer(TransformerMixin):\n",
    "#     def fit(self, X, y=None):\n",
    "#         self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "#         if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "#         index=X.columns)\n",
    "#         return self\n",
    "#     def transform(self, X, y=None):\n",
    "#         return X.fillna(self.fill)\n",
    "# df_values = DataFrameImputer().fit_transform(df_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy values\n",
    "X_all = df_values.values\n",
    "print(X_all.shape)\n",
    "\n",
    "X_train = X_all[:num_train]\n",
    "X_test = X_all[num_train:]\n",
    "\n",
    "df_columns = df_values.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1,\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_output = xgb.cv(xgb_params, dtrain, nfold=5, num_boost_round=1000, early_stopping_rounds=20,\n",
    "    verbose_eval=20, show_stdv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv_scores = []\n",
    "# kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\n",
    "# for dev_index, val_index in kf.split(range(X_train.shape[0])):\n",
    "#         dev_X, val_X = X_train[dev_index,:], X_train[val_index,:]\n",
    "#         dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "#         reg.fit(dev_X, dev_y)\n",
    "#         preds = reg.predict(val_X)\n",
    "#         cv_scores.append(np.sqrt(mean_squared_error(val_y, preds)))\n",
    "#         print cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(cv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_boost_rounds = 500\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 16))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)\n",
    "\n",
    "df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
    "\n",
    "df_sub.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['price_doc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
